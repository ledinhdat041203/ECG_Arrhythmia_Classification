{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Normal': 0, 'Bundle bra': 1, 'Supraventr': 2, 'Ventricula': 3, 'escape': 4}\n"
     ]
    }
   ],
   "source": [
    "with open('labels.json', 'r') as json_file:\n",
    "    label_to_number  = json.load(json_file)\n",
    "\n",
    "print(label_to_number )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([([[-0.145, -0.065], [-0.145, -0.065], [-0.145, -0.065], ..., [-0.39 , -0.295], [-0.4  , -0.29 ], [-0.405, -0.285]], 'Supraventr'),\n",
       "       ([[-0.535, -0.05 ], [-0.505,  0.085], [-0.415,  0.195], ..., [-0.365, -0.255], [-0.375, -0.265], [-0.375, -0.26 ]], 'Supraventr'),\n",
       "       ([[-0.39 , -0.275], [-0.395, -0.265], [-0.39 , -0.285], ..., [-0.425, -0.4  ], [-0.43 , -0.42 ], [-0.42 , -0.4  ]], 'Normal'),\n",
       "       ...,\n",
       "       ([[-0.22 ,  0.01 ], [-0.205,  0.03 ], [-0.215,  0.035], ..., [-0.42 ,  0.005], [-0.41 , -0.01 ], [-0.395, -0.025]], 'Normal'),\n",
       "       ([[-0.2  ,  0.185], [-0.215,  0.165], [-0.21 ,  0.17 ], ..., [-0.235,  0.16 ], [-0.24 ,  0.165], [-0.25 ,  0.155]], 'Normal'),\n",
       "       ([[-0.395, -0.015], [-0.4  , -0.005], [-0.42 , -0.015], ..., [-0.395,  0.005], [-0.38 , -0.01 ], [-0.385,  0.01 ]], 'Normal')],\n",
       "      shape=(16006,), dtype=[('segment', '<f4', (3600, 2)), ('label', '<U10')])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.load('data_tranning.npy', allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Bundle bra', 'Normal', 'Supraventr', 'Ventricula', 'escape'],\n",
       "      dtype='<U10')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segments = data['segment']  \n",
    "labels = data['label']  \n",
    "np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [label_to_number.get(label, -1) for label in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 3,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 2,\n",
       " 2,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " ...]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(segments, labels, test_size=0.3, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "\n",
    "y_train = torch.tensor(y_train, dtype=torch.long)\n",
    "y_val = torch.tensor(y_val, dtype=torch.long)\n",
    "y_test = torch.tensor(y_test, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ECGDataset(Dataset):\n",
    "    def __init__(self, segments, labels):\n",
    "        self.segments = segments\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.segments)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.segments[idx], self.labels[idx]\n",
    "\n",
    "# Tạo Dataset và DataLoader\n",
    "train_dataset = ECGDataset(X_train, y_train)\n",
    "val_dataset = ECGDataset(X_val, y_val)\n",
    "test_dataset = ECGDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([64, 3600, 2])\n",
      "Label shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "# Duyệt 1 batch từ train_loader\n",
    "for inputs, labels in train_loader:\n",
    "    print(f\"Input shape: {inputs.shape}\")\n",
    "    print(f\"Label shape: {labels.shape}\")\n",
    "    break  # Chỉ lấy batch đầu tiên\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ECG_CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ECG_CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=16, kernel_size=7, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(16)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(16, 32, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv3 = nn.Conv1d(32, 64, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.pool3 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)  # Tự động thu nhỏ chiều L về 1\n",
    "        self.fc = nn.Linear(64, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool1(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool3(F.relu(self.bn3(self.conv3(x))))\n",
    "        x = self.global_pool(x).squeeze(-1)  # (B, 64)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ECG_CNN(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.4134, Train Accuracy: 85.40%, Validation Loss: 0.5197, Validation Accuracy: 82.30%\n",
      "Epoch [2/100], Train Loss: 0.4012, Train Accuracy: 86.09%, Validation Loss: 0.4473, Validation Accuracy: 84.56%\n",
      "Epoch [3/100], Train Loss: 0.3917, Train Accuracy: 86.06%, Validation Loss: 0.4784, Validation Accuracy: 81.92%\n",
      "Epoch [4/100], Train Loss: 0.3892, Train Accuracy: 86.15%, Validation Loss: 0.6870, Validation Accuracy: 75.82%\n",
      "Epoch [5/100], Train Loss: 0.3785, Train Accuracy: 86.62%, Validation Loss: 0.4882, Validation Accuracy: 81.59%\n",
      "Epoch [6/100], Train Loss: 0.3684, Train Accuracy: 86.64%, Validation Loss: 0.3993, Validation Accuracy: 85.87%\n",
      "Epoch [7/100], Train Loss: 0.3538, Train Accuracy: 87.67%, Validation Loss: 0.4180, Validation Accuracy: 84.74%\n",
      "Epoch [8/100], Train Loss: 0.3431, Train Accuracy: 87.62%, Validation Loss: 0.3643, Validation Accuracy: 86.73%\n",
      "Epoch [9/100], Train Loss: 0.3462, Train Accuracy: 87.45%, Validation Loss: 0.3970, Validation Accuracy: 85.78%\n",
      "Epoch [10/100], Train Loss: 0.3452, Train Accuracy: 87.27%, Validation Loss: 0.4552, Validation Accuracy: 83.64%\n",
      "Epoch [11/100], Train Loss: 0.3347, Train Accuracy: 87.94%, Validation Loss: 0.3442, Validation Accuracy: 87.15%\n",
      "Epoch [12/100], Train Loss: 0.3235, Train Accuracy: 88.18%, Validation Loss: 0.3506, Validation Accuracy: 87.63%\n",
      "Epoch [13/100], Train Loss: 0.3268, Train Accuracy: 88.13%, Validation Loss: 0.3521, Validation Accuracy: 86.50%\n",
      "Epoch [14/100], Train Loss: 0.3246, Train Accuracy: 88.00%, Validation Loss: 0.3357, Validation Accuracy: 87.86%\n",
      "Epoch [15/100], Train Loss: 0.3276, Train Accuracy: 87.83%, Validation Loss: 0.3595, Validation Accuracy: 86.59%\n",
      "Epoch [16/100], Train Loss: 0.3089, Train Accuracy: 88.88%, Validation Loss: 0.3373, Validation Accuracy: 88.28%\n",
      "Epoch [17/100], Train Loss: 0.3171, Train Accuracy: 87.91%, Validation Loss: 0.3465, Validation Accuracy: 87.18%\n",
      "Epoch [18/100], Train Loss: 0.3124, Train Accuracy: 88.55%, Validation Loss: 0.3724, Validation Accuracy: 86.56%\n",
      "Epoch [19/100], Train Loss: 0.3030, Train Accuracy: 88.82%, Validation Loss: 0.3517, Validation Accuracy: 87.51%\n",
      "Epoch [20/100], Train Loss: 0.3175, Train Accuracy: 88.37%, Validation Loss: 0.3546, Validation Accuracy: 87.06%\n",
      "Epoch [21/100], Train Loss: 0.3032, Train Accuracy: 88.80%, Validation Loss: 0.3560, Validation Accuracy: 86.50%\n",
      "Epoch [22/100], Train Loss: 0.2969, Train Accuracy: 89.00%, Validation Loss: 0.3039, Validation Accuracy: 88.58%\n",
      "Epoch [23/100], Train Loss: 0.2899, Train Accuracy: 89.07%, Validation Loss: 0.5098, Validation Accuracy: 82.15%\n",
      "Epoch [24/100], Train Loss: 0.2915, Train Accuracy: 89.03%, Validation Loss: 0.3643, Validation Accuracy: 85.22%\n",
      "Epoch [25/100], Train Loss: 0.2880, Train Accuracy: 89.56%, Validation Loss: 0.2942, Validation Accuracy: 89.32%\n",
      "Epoch [26/100], Train Loss: 0.2774, Train Accuracy: 89.53%, Validation Loss: 0.3101, Validation Accuracy: 87.66%\n",
      "Epoch [27/100], Train Loss: 0.2958, Train Accuracy: 89.40%, Validation Loss: 0.3053, Validation Accuracy: 89.23%\n",
      "Epoch [28/100], Train Loss: 0.2766, Train Accuracy: 89.47%, Validation Loss: 0.3024, Validation Accuracy: 88.85%\n",
      "Epoch [29/100], Train Loss: 0.2850, Train Accuracy: 89.29%, Validation Loss: 0.3040, Validation Accuracy: 89.53%\n",
      "Epoch [30/100], Train Loss: 0.2827, Train Accuracy: 89.51%, Validation Loss: 0.3720, Validation Accuracy: 85.51%\n",
      "Epoch [31/100], Train Loss: 0.2774, Train Accuracy: 89.43%, Validation Loss: 0.2951, Validation Accuracy: 89.08%\n",
      "Epoch [32/100], Train Loss: 0.2665, Train Accuracy: 89.73%, Validation Loss: 0.2967, Validation Accuracy: 89.41%\n",
      "Epoch [33/100], Train Loss: 0.2721, Train Accuracy: 89.80%, Validation Loss: 0.2907, Validation Accuracy: 89.68%\n",
      "Epoch [34/100], Train Loss: 0.2611, Train Accuracy: 90.26%, Validation Loss: 0.5269, Validation Accuracy: 80.84%\n",
      "Epoch [35/100], Train Loss: 0.2676, Train Accuracy: 89.90%, Validation Loss: 0.2873, Validation Accuracy: 88.85%\n",
      "Epoch [36/100], Train Loss: 0.2598, Train Accuracy: 90.14%, Validation Loss: 0.2795, Validation Accuracy: 90.12%\n",
      "Epoch [37/100], Train Loss: 0.2597, Train Accuracy: 90.03%, Validation Loss: 0.3469, Validation Accuracy: 87.30%\n",
      "Epoch [38/100], Train Loss: 0.2582, Train Accuracy: 90.37%, Validation Loss: 0.2821, Validation Accuracy: 89.32%\n",
      "Epoch [39/100], Train Loss: 0.2689, Train Accuracy: 89.91%, Validation Loss: 0.2880, Validation Accuracy: 89.80%\n",
      "Epoch [40/100], Train Loss: 0.2655, Train Accuracy: 90.09%, Validation Loss: 0.2910, Validation Accuracy: 88.99%\n",
      "Epoch [41/100], Train Loss: 0.2537, Train Accuracy: 90.56%, Validation Loss: 0.3208, Validation Accuracy: 88.37%\n",
      "Epoch [42/100], Train Loss: 0.2511, Train Accuracy: 90.75%, Validation Loss: 0.2732, Validation Accuracy: 89.77%\n",
      "Epoch [43/100], Train Loss: 0.2512, Train Accuracy: 90.32%, Validation Loss: 0.3224, Validation Accuracy: 88.85%\n",
      "Epoch [44/100], Train Loss: 0.2541, Train Accuracy: 90.64%, Validation Loss: 0.2747, Validation Accuracy: 89.98%\n",
      "Epoch [45/100], Train Loss: 0.2444, Train Accuracy: 90.78%, Validation Loss: 0.2794, Validation Accuracy: 89.65%\n",
      "Epoch [46/100], Train Loss: 0.2595, Train Accuracy: 90.22%, Validation Loss: 0.2904, Validation Accuracy: 89.05%\n",
      "Epoch [47/100], Train Loss: 0.2472, Train Accuracy: 90.79%, Validation Loss: 0.2678, Validation Accuracy: 90.69%\n",
      "Epoch [48/100], Train Loss: 0.2430, Train Accuracy: 90.98%, Validation Loss: 0.2938, Validation Accuracy: 88.96%\n",
      "Epoch [49/100], Train Loss: 0.2372, Train Accuracy: 91.21%, Validation Loss: 0.2906, Validation Accuracy: 89.35%\n",
      "Epoch [50/100], Train Loss: 0.2413, Train Accuracy: 90.95%, Validation Loss: 0.3755, Validation Accuracy: 86.08%\n",
      "Epoch [51/100], Train Loss: 0.2415, Train Accuracy: 91.26%, Validation Loss: 0.2620, Validation Accuracy: 90.45%\n",
      "Epoch [52/100], Train Loss: 0.2335, Train Accuracy: 91.14%, Validation Loss: 0.2900, Validation Accuracy: 90.10%\n",
      "Epoch [53/100], Train Loss: 0.2394, Train Accuracy: 91.02%, Validation Loss: 0.2674, Validation Accuracy: 90.99%\n",
      "Epoch [54/100], Train Loss: 0.2379, Train Accuracy: 91.15%, Validation Loss: 0.2678, Validation Accuracy: 89.80%\n",
      "Epoch [55/100], Train Loss: 0.2255, Train Accuracy: 91.75%, Validation Loss: 0.3489, Validation Accuracy: 87.92%\n",
      "Epoch [56/100], Train Loss: 0.2315, Train Accuracy: 91.39%, Validation Loss: 0.2503, Validation Accuracy: 91.08%\n",
      "Epoch [57/100], Train Loss: 0.2252, Train Accuracy: 91.34%, Validation Loss: 0.2789, Validation Accuracy: 90.33%\n",
      "Epoch [58/100], Train Loss: 0.2306, Train Accuracy: 91.25%, Validation Loss: 0.2483, Validation Accuracy: 91.14%\n",
      "Epoch [59/100], Train Loss: 0.2192, Train Accuracy: 92.09%, Validation Loss: 0.3050, Validation Accuracy: 88.73%\n",
      "Epoch [60/100], Train Loss: 0.2141, Train Accuracy: 92.04%, Validation Loss: 0.3000, Validation Accuracy: 89.08%\n",
      "Epoch [61/100], Train Loss: 0.2140, Train Accuracy: 92.12%, Validation Loss: 0.2749, Validation Accuracy: 90.18%\n",
      "Epoch [62/100], Train Loss: 0.2233, Train Accuracy: 91.66%, Validation Loss: 0.3246, Validation Accuracy: 87.33%\n",
      "Epoch [63/100], Train Loss: 0.2162, Train Accuracy: 91.92%, Validation Loss: 0.2512, Validation Accuracy: 90.81%\n",
      "Epoch [64/100], Train Loss: 0.2170, Train Accuracy: 91.92%, Validation Loss: 0.2657, Validation Accuracy: 90.60%\n",
      "Epoch [65/100], Train Loss: 0.2133, Train Accuracy: 92.23%, Validation Loss: 0.2742, Validation Accuracy: 90.07%\n",
      "Epoch [66/100], Train Loss: 0.2109, Train Accuracy: 92.16%, Validation Loss: 0.3690, Validation Accuracy: 87.06%\n",
      "Epoch [67/100], Train Loss: 0.2090, Train Accuracy: 92.46%, Validation Loss: 0.2754, Validation Accuracy: 89.56%\n",
      "Epoch [68/100], Train Loss: 0.2205, Train Accuracy: 91.94%, Validation Loss: 0.2698, Validation Accuracy: 90.54%\n",
      "Epoch [69/100], Train Loss: 0.2049, Train Accuracy: 92.77%, Validation Loss: 0.2595, Validation Accuracy: 90.51%\n",
      "Epoch [70/100], Train Loss: 0.2240, Train Accuracy: 91.55%, Validation Loss: 0.2428, Validation Accuracy: 91.31%\n",
      "Epoch [71/100], Train Loss: 0.2018, Train Accuracy: 92.73%, Validation Loss: 0.2522, Validation Accuracy: 91.31%\n",
      "Epoch [72/100], Train Loss: 0.2082, Train Accuracy: 92.32%, Validation Loss: 0.3538, Validation Accuracy: 86.53%\n",
      "Epoch [73/100], Train Loss: 0.2074, Train Accuracy: 92.63%, Validation Loss: 0.2648, Validation Accuracy: 90.21%\n",
      "Epoch [74/100], Train Loss: 0.2006, Train Accuracy: 92.63%, Validation Loss: 0.2442, Validation Accuracy: 91.31%\n",
      "Epoch [75/100], Train Loss: 0.2036, Train Accuracy: 92.73%, Validation Loss: 0.2441, Validation Accuracy: 91.23%\n",
      "Epoch [76/100], Train Loss: 0.1955, Train Accuracy: 92.73%, Validation Loss: 0.2420, Validation Accuracy: 92.00%\n",
      "Epoch [77/100], Train Loss: 0.1987, Train Accuracy: 92.85%, Validation Loss: 0.2296, Validation Accuracy: 91.94%\n",
      "Epoch [78/100], Train Loss: 0.1987, Train Accuracy: 92.65%, Validation Loss: 0.2298, Validation Accuracy: 92.21%\n",
      "Epoch [79/100], Train Loss: 0.1975, Train Accuracy: 92.76%, Validation Loss: 0.2318, Validation Accuracy: 92.00%\n",
      "Epoch [80/100], Train Loss: 0.1940, Train Accuracy: 92.99%, Validation Loss: 0.2526, Validation Accuracy: 91.46%\n",
      "Epoch [81/100], Train Loss: 0.1951, Train Accuracy: 92.78%, Validation Loss: 0.2367, Validation Accuracy: 91.52%\n",
      "Epoch [82/100], Train Loss: 0.2031, Train Accuracy: 92.74%, Validation Loss: 0.2506, Validation Accuracy: 91.11%\n",
      "Epoch [83/100], Train Loss: 0.1947, Train Accuracy: 93.14%, Validation Loss: 0.2683, Validation Accuracy: 90.99%\n",
      "Epoch [84/100], Train Loss: 0.2082, Train Accuracy: 92.48%, Validation Loss: 0.2363, Validation Accuracy: 91.40%\n",
      "Epoch [85/100], Train Loss: 0.2001, Train Accuracy: 92.68%, Validation Loss: 0.2363, Validation Accuracy: 91.70%\n",
      "Epoch [86/100], Train Loss: 0.1920, Train Accuracy: 93.19%, Validation Loss: 0.2387, Validation Accuracy: 92.00%\n",
      "Epoch [87/100], Train Loss: 0.1874, Train Accuracy: 93.22%, Validation Loss: 0.2220, Validation Accuracy: 92.62%\n",
      "Epoch [88/100], Train Loss: 0.1882, Train Accuracy: 93.11%, Validation Loss: 0.2488, Validation Accuracy: 92.21%\n",
      "Epoch [89/100], Train Loss: 0.1813, Train Accuracy: 93.41%, Validation Loss: 0.2267, Validation Accuracy: 92.12%\n",
      "Epoch [90/100], Train Loss: 0.1852, Train Accuracy: 93.45%, Validation Loss: 0.2835, Validation Accuracy: 89.26%\n",
      "Epoch [91/100], Train Loss: 0.1841, Train Accuracy: 93.43%, Validation Loss: 0.3015, Validation Accuracy: 89.14%\n",
      "Epoch [92/100], Train Loss: 0.1930, Train Accuracy: 93.11%, Validation Loss: 0.2443, Validation Accuracy: 91.40%\n",
      "Epoch [93/100], Train Loss: 0.1835, Train Accuracy: 93.15%, Validation Loss: 0.2417, Validation Accuracy: 91.40%\n",
      "Epoch [94/100], Train Loss: 0.1869, Train Accuracy: 93.19%, Validation Loss: 0.2362, Validation Accuracy: 92.15%\n",
      "Epoch [95/100], Train Loss: 0.1770, Train Accuracy: 93.64%, Validation Loss: 0.3096, Validation Accuracy: 88.10%\n",
      "Epoch [96/100], Train Loss: 0.1776, Train Accuracy: 93.68%, Validation Loss: 0.2364, Validation Accuracy: 91.31%\n",
      "Epoch [97/100], Train Loss: 0.1803, Train Accuracy: 93.62%, Validation Loss: 0.2425, Validation Accuracy: 91.28%\n",
      "Epoch [98/100], Train Loss: 0.1768, Train Accuracy: 93.64%, Validation Loss: 0.2288, Validation Accuracy: 92.06%\n",
      "Epoch [99/100], Train Loss: 0.1781, Train Accuracy: 93.69%, Validation Loss: 0.2131, Validation Accuracy: 92.68%\n",
      "Epoch [100/100], Train Loss: 0.1863, Train Accuracy: 93.24%, Validation Loss: 0.2161, Validation Accuracy: 92.47%\n"
     ]
    }
   ],
   "source": [
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            # inputs = inputs.unsqueeze(1)  \n",
    "            inputs = inputs.permute(0, 2, 1) \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            \n",
    "            predicted = outputs.argmax(dim=1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        epoch_accuracy = 100 * correct / total\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs = inputs.permute(0, 2, 1) \n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predicted = outputs.argmax(dim=1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "        val_loss = val_loss / len(val_loader)\n",
    "        val_accuracy = 100 * val_correct / val_total\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Train Loss: {epoch_loss:.4f}, Train Accuracy: {epoch_accuracy:.2f}%, \"\n",
    "              f\"Validation Loss: {val_loss:.4f}, Validation Accuracy: {val_accuracy:.2f}%\")\n",
    "\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
